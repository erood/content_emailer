{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#important command line function to get mongo uri -- \n",
    "# heroku config --app sheltered-ocean-45405 | grep MONGODB_URI\n",
    "#where you literally type in MONGODB_URI, generates code like such: mongodb://heroku_xph57032:sb1vurrej7o36g0jumoh534qpr@ds141108.mlab.com:41108/heroku_xph57032\n",
    "#the code is then fed into the client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mongo connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import numpy as np\n",
    "import csv, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://heroku_zt5q0wf3:nl2kmh3nvs201j76if1d60f2h6@ds127883.mlab.com:27883/heroku_zt5q0wf3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client['heroku_zt5q0wf3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records = db.records\n",
    "records = pd.DataFrame(list(records.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domains = db.domains\n",
    "domains = pd.DataFrame(list(domains.find()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records.to_csv('/Users/erikrood/desktop/records_12_14_17.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main working push (as of 8/24/17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 8/21/17 Working URL Scrape (proof of concept)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import praw\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "\n",
    "#set up DB\n",
    "#local\n",
    "#client = MongoClient('mongodb://localhost:27017/test')\n",
    "#db = client.test\n",
    "\n",
    "#set up praw\n",
    "reddit = praw.Reddit(client_id='D7tXhzmCZKD1Ig',\n",
    "                     client_secret='a8Cs1yp7GUakwc-Hzkd1twMRRcU',\n",
    "                     user_agent='Script for top domains posted on reddit')\n",
    "\n",
    "#create list of subreddits to include\n",
    "#create list of subreddits to include\n",
    "s_list = \\\n",
    "[\n",
    "'funny',\n",
    "'todayilearned',\n",
    "'science',\n",
    "'worldnews',\n",
    "'pics',\n",
    "'IAmA',\n",
    "'gaming',\n",
    "'videos',\n",
    "'movies',\n",
    "'blog',\n",
    "'Music',\n",
    "'aww',\n",
    "'gifs',\n",
    "'news',\n",
    "'askscience',\n",
    "'EarthPorn',\n",
    "'books',\n",
    "'television',\n",
    "'LifeProTips',\n",
    "'mildlyinteresting',\n",
    "'space',\n",
    "'Showerthoughts',\n",
    "'DIY',\n",
    "'Jokes',\n",
    "'sports',\n",
    "'gadgets',\n",
    "'tifu',\n",
    "'InternetIsBeautiful',\n",
    "'nottheonion',\n",
    "'photoshopbattles',\n",
    "'food',\n",
    "'history',\n",
    "'Futurology',\n",
    "'Documentaries',\n",
    "'dataisbeautiful',\n",
    "'personalfinance',\n",
    "'listentothis',\n",
    "'UpliftingNews',\n",
    "'GetMotivated',\n",
    "'OldSchoolCool',\n",
    "'philosophy',\n",
    "'Art',\n",
    "'nosleep',\n",
    "'creepy',\n",
    "'WritingPrompts',\n",
    "'TwoXChromosomes',\n",
    "'Fitness',\n",
    "'technology',\n",
    "'WTF',\n",
    "'bestof',\n",
    "'AdviceAnimals',\n",
    "'politics',\n",
    "'atheism',\n",
    "'europe',\n",
    "'interestingasfuck',\n",
    "'woahdude',\n",
    "'leagueoflegends',\n",
    "'pcmasterrace',\n",
    "'BlackPeopleTwitter',\n",
    "'gameofthrones',\n",
    "'trees',\n",
    "'reactiongifs',\n",
    "'Unexpected',\n",
    "'Overwatch',\n",
    "'Android',\n",
    "'oddlysatisfying',\n",
    "'Games',\n",
    "'programming',\n",
    "'wholesomememes',\n",
    "'nba',\n",
    "'cringepics',\n",
    "'facepalm',\n",
    "'me_irl',\n",
    "'reddit.com',\n",
    "'sex',\n",
    "'relationships',\n",
    "'Frugal',\n",
    "'pokemon',\n",
    "'soccer',\n",
    "'lifehacks',\n",
    "'pokemongo',\n",
    "'ImGoingToHellForThis',\n",
    "'fffffffuuuuuuuuuuuu',\n",
    "'tattoos',\n",
    "'comics',\n",
    "'malefashionadvice',\n",
    "'OutOfTheLoop',\n",
    "'StarWars',\n",
    "'CrappyDesign',\n",
    "'YouShouldKnow',\n",
    "'AskHistorians',\n",
    "'nfl',\n",
    "'HistoryPorn',\n",
    "'buildapc',\n",
    "'RoastMe',\n",
    "'FoodPorn',\n",
    "'loseit',\n",
    "'AnimalsBeingJerks',\n",
    "'cringe',\n",
    "'PS4',\n",
    "'dankmemes',\n",
    "'rickandmorty',\n",
    "'Whatcouldgowrong',\n",
    "'baseball',\n",
    "'travel',\n",
    "'hiphopheads',\n",
    "'FiftyFifty',\n",
    "'RoomPorn',\n",
    "'NatureIsFuckingLit',\n",
    "'wheredidthesodago',\n",
    "'Eyebleach',\n",
    "'anime',\n",
    "'GlobalOffensive',\n",
    "'hearthstone',\n",
    "'Cooking',\n",
    "'freebies',\n",
    "'mildlyinfuriating',\n",
    "'xboxone',\n",
    "'HighQualityGifs',\n",
    "'youtubehaiku',\n",
    "'JusticePorn',\n",
    "'GifRecipes',\n",
    "'bodyweightfitness',\n",
    "'The_Donald',\n",
    "'conspiracy',\n",
    "'Tinder',\n",
    "'Minecraft',\n",
    "'cats',\n",
    "'AnimalsBeingBros',\n",
    "'GameDeals',\n",
    "'talesfromtechsupport',\n",
    "'comicbooks',\n",
    "'EatCheapAndHealthy',\n",
    "'holdmybeer',\n",
    "'nonononoyes',\n",
    "'hockey',\n",
    "'trashy',\n",
    "'scifi',\n",
    "'Steam',\n",
    "'apple',\n",
    "'skyrim',\n",
    "'instant_regret',\n",
    "'quityourbullshit',\n",
    "'shittyaskscience',\n",
    "'thatHappened',\n",
    "'wallpapers',\n",
    "'itookapicture',\n",
    "'iamverysmart',\n",
    "'wow',\n",
    "'changemyview',\n",
    "'AbandonedPorn',\n",
    "'FanTheories',\n",
    "'woodworking',\n",
    "'trippinthroughtime',\n",
    "'NetflixBestOf',\n",
    "'investing',\n",
    "'oldpeoplefacebook',\n",
    "'AskMen',\n",
    "'MakeupAddiction',\n",
    "'Economics',\n",
    "'pcgaming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>domain</th>\n",
       "      <th>update_date</th>\n",
       "      <th>self_check</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7356dq</td>\n",
       "      <td>DIY</td>\n",
       "      <td>1075</td>\n",
       "      <td>imgur.com</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>imgu</td>\n",
       "      <td>www.reddit.com/7356dq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75507c</td>\n",
       "      <td>aww</td>\n",
       "      <td>79100</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>i.im</td>\n",
       "      <td>www.reddit.com/75507c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75hkbe</td>\n",
       "      <td>FoodPorn</td>\n",
       "      <td>850</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>i.re</td>\n",
       "      <td>www.reddit.com/75hkbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>729yey</td>\n",
       "      <td>wheredidthesodago</td>\n",
       "      <td>1416</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>i.re</td>\n",
       "      <td>www.reddit.com/729yey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>763jwv</td>\n",
       "      <td>dankmemes</td>\n",
       "      <td>32960</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>i.re</td>\n",
       "      <td>www.reddit.com/763jwv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          subreddit  score       domain update_date self_check  \\\n",
       "1  7356dq                DIY   1075    imgur.com  10/21/2017       imgu   \n",
       "2  75507c                aww  79100  i.imgur.com  10/21/2017       i.im   \n",
       "3  75hkbe           FoodPorn    850    i.redd.it  10/21/2017       i.re   \n",
       "4  729yey  wheredidthesodago   1416    i.redd.it  10/21/2017       i.re   \n",
       "6  763jwv          dankmemes  32960    i.redd.it  10/21/2017       i.re   \n",
       "\n",
       "                     url  \n",
       "1  www.reddit.com/7356dq  \n",
       "2  www.reddit.com/75507c  \n",
       "3  www.reddit.com/75hkbe  \n",
       "4  www.reddit.com/729yey  \n",
       "6  www.reddit.com/763jwv  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains_sub = {}\n",
    "domains = {}\n",
    "domains_score = {}\n",
    "domains_url = {}\n",
    "\n",
    "for i in s_list:\n",
    "\n",
    "    #pull in score\n",
    "    subreddit = reddit.subreddit(i)   #input('enter subreddit name: /r/'))\n",
    "    submissions = subreddit.top('month', limit=50)\n",
    "\n",
    "\n",
    "    for s in submissions:\n",
    "        if s.id in domains_score.keys():\n",
    "            #(1) works for generating total score:\n",
    "            domains_score[s.id] += s.score\n",
    "        else:\n",
    "            #(2)\n",
    "            #works for generating total score:\n",
    "            domains_score[s.id] = s.score\n",
    "\n",
    "    df_score = pd.DataFrame.from_dict(domains_score, orient='index').reset_index()\n",
    "    df_score.columns = ['id','score']\n",
    "    \n",
    "    #pull in domain\n",
    "    subreddit = reddit.subreddit(i)   #input('enter subreddit name: /r/'))\n",
    "    submissions = subreddit.top('month', limit=50)\n",
    "\n",
    "\n",
    "    for s in submissions:\n",
    "        if s.id in domains.keys():\n",
    "            #(1) works for generating total score:\n",
    "            domains[s.id] = s.domain\n",
    "        else:\n",
    "            #(2)\n",
    "            #works for generating total score:\n",
    "            domains[s.id] = s.domain\n",
    "\n",
    "    df_domain = pd.DataFrame.from_dict(domains, orient='index').reset_index()\n",
    "    df_domain.columns = ['id','domain']\n",
    "    \n",
    "    #pull in url  - does not work because I'm aggregating up for the rest of the above\n",
    "    subreddit = reddit.subreddit(i)   #input('enter subreddit name: /r/'))\n",
    "    submissions = subreddit.top('month', limit=50)\n",
    "\n",
    "\n",
    "    for s in submissions:\n",
    "        if s.id in domains_url.keys():\n",
    "            #(1) works for generating total score:\n",
    "            domains_url[s.id] = s.url\n",
    "        else:\n",
    "            #(2)\n",
    "            #works for generating total score:\n",
    "            domains_url[s.id] = s.url\n",
    "\n",
    "    df_url = pd.DataFrame.from_dict(domains_url, orient='index').reset_index()\n",
    "    df_url.columns = ['id','url']\n",
    "\n",
    "    #pull in subreddit\n",
    "    subreddit = reddit.subreddit(i)\n",
    "    submissions = subreddit.top('month', limit=50)\n",
    "\n",
    "\n",
    "    for s in submissions:\n",
    "        if s.id in domains_sub.keys():\n",
    "            #(1) works for generating total score:\n",
    "            domains_sub[s.id] = s.subreddit.display_name\n",
    "        else:\n",
    "            #(2)\n",
    "            #works for generating total score:\n",
    "            domains_sub[s.id] = s.subreddit.display_name\n",
    "\n",
    "\n",
    "df_subreddit = pd.DataFrame.from_dict(domains_sub, orient='index').reset_index()\n",
    "df_subreddit.columns = ['id','subreddit']\n",
    "\n",
    "\n",
    "#post processing\n",
    "df_sub_score = df_subreddit.merge(df_score, how='left', on=\"id\")\n",
    "df_final = df_sub_score.merge(df_domain, how='left', on='id')\n",
    "#df3 = df_submissions_score.merge(df_subreddit, how='left', on='domain')\n",
    "#df3 = df3.sort_values(by='submissions', ascending=0)\n",
    "#df3['avg_score'] = (df3.score/df3.submissions)\n",
    "# Create a list to store current date\n",
    "date = []\n",
    "# For each row in the column,\n",
    "for row in df_final['id']:\n",
    "    # Append a letter grade\n",
    "    date.append(time.strftime(\"%m/%d/%Y\"))\n",
    "# Create a column from the list\n",
    "df_final['update_date'] = date\n",
    "\n",
    "df_final['self_check'] = df_final['domain'].str[:4]\n",
    "df_final = df_final[df_final.self_check != 'self']\n",
    "df_final['url'] = ['www.reddit.com/']+df_final['id'].astype(str) \n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "# wildcard search notes: https://stackoverflow.com/questions/11427138/python-wildcard-search-in-string\n",
    "# Classify domains as image platform, video platform, etc\n",
    "classify = []\n",
    "\n",
    "# For each row in the column,\n",
    "for row in df_final['domain']:\n",
    "    # image/video\n",
    "    if row in ['i.redd.it','m.imgur.com','i.imgur.com','imgur.com',\\\n",
    "               'gfycat.com','media.giphy.com','instagram.com','gfycat.com',\\\n",
    "               'c1.staticflickr.com','68.media.tumblr.com','media.tumblr.com',\\\n",
    "               'flickr.com','zippy.gfycat.com', 'v.redd.it','i.imgflip.com']:\n",
    "        classify.append('image/video')\n",
    "    # image/video\n",
    "    elif row in ['youtube.com','youtu.be','streamable.com','m.youtube.com',\\\n",
    "                 'clips.twitch.tv','netflix.com']:\n",
    "        # Append a letter grade\n",
    "        classify.append('image/video')\n",
    "    #social    \n",
    "    elif row in ['twitter.com','facebook.com']:\n",
    "        # Append a letter grade\n",
    "        classify.append('social')\n",
    "    else:\n",
    "        # Append a failing grade\n",
    "        classify.append('other')\n",
    "\n",
    "# Create a column from the list\n",
    "df_final['classify'] = classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>domain</th>\n",
       "      <th>update_date</th>\n",
       "      <th>self_check</th>\n",
       "      <th>url</th>\n",
       "      <th>classify</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7356dq</td>\n",
       "      <td>DIY</td>\n",
       "      <td>1075</td>\n",
       "      <td>imgur.com</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>imgu</td>\n",
       "      <td>www.reddit.com/7356dq</td>\n",
       "      <td>image/video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75507c</td>\n",
       "      <td>aww</td>\n",
       "      <td>79100</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>i.im</td>\n",
       "      <td>www.reddit.com/75507c</td>\n",
       "      <td>image/video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75hkbe</td>\n",
       "      <td>FoodPorn</td>\n",
       "      <td>850</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>i.re</td>\n",
       "      <td>www.reddit.com/75hkbe</td>\n",
       "      <td>image/video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>729yey</td>\n",
       "      <td>wheredidthesodago</td>\n",
       "      <td>1416</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>i.re</td>\n",
       "      <td>www.reddit.com/729yey</td>\n",
       "      <td>image/video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>763jwv</td>\n",
       "      <td>dankmemes</td>\n",
       "      <td>32960</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>i.re</td>\n",
       "      <td>www.reddit.com/763jwv</td>\n",
       "      <td>image/video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          subreddit  score       domain update_date self_check  \\\n",
       "1  7356dq                DIY   1075    imgur.com  10/21/2017       imgu   \n",
       "2  75507c                aww  79100  i.imgur.com  10/21/2017       i.im   \n",
       "3  75hkbe           FoodPorn    850    i.redd.it  10/21/2017       i.re   \n",
       "4  729yey  wheredidthesodago   1416    i.redd.it  10/21/2017       i.re   \n",
       "6  763jwv          dankmemes  32960    i.redd.it  10/21/2017       i.re   \n",
       "\n",
       "                     url     classify  \n",
       "1  www.reddit.com/7356dq  image/video  \n",
       "2  www.reddit.com/75507c  image/video  \n",
       "3  www.reddit.com/75hkbe  image/video  \n",
       "4  www.reddit.com/729yey  image/video  \n",
       "6  www.reddit.com/763jwv  image/video  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>classify</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>wow</td>\n",
       "      <td>image/video</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>youtubehaiku</td>\n",
       "      <td>image/video</td>\n",
       "      <td>9045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>zapals.com</td>\n",
       "      <td>freebies</td>\n",
       "      <td>other</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>zdnet.com</td>\n",
       "      <td>gadgets</td>\n",
       "      <td>other</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>zerohedge.com</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>other</td>\n",
       "      <td>3008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             domain     subreddit     classify  avg_score\n",
       "1527    youtube.com           wow  image/video       1831\n",
       "1528    youtube.com  youtubehaiku  image/video       9045\n",
       "1529     zapals.com      freebies        other        266\n",
       "1530      zdnet.com       gadgets        other        156\n",
       "1531  zerohedge.com    conspiracy        other       3008"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['subreddit'] = df_final['subreddit'].str.lower()\n",
    "df_pivot_avg = df_final.groupby(['domain', 'subreddit','classify']).mean().reset_index()\n",
    "df_pivot_avg.columns = [['domain','subreddit','classify', 'avg_score']]\n",
    "df_pivot_avg.avg_score = df_pivot_avg.avg_score.astype(int)\n",
    "df_pivot_avg.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>classify</th>\n",
       "      <th>submissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.bp.blogspot.com</td>\n",
       "      <td>travel</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11alive.com</td>\n",
       "      <td>upliftingnews</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12160.info</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1800contacts.com</td>\n",
       "      <td>freebies</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.media.tumblr.com</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                domain      subreddit classify  submissions\n",
       "0    1.bp.blogspot.com         travel    other            1\n",
       "1          11alive.com  upliftingnews    other            1\n",
       "2           12160.info     conspiracy    other            1\n",
       "3     1800contacts.com       freebies    other            1\n",
       "4  24.media.tumblr.com     reddit.com    other            1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_count = df_final[['domain','subreddit','classify', 'score']]\n",
    "df_pivot_count = df_pivot_count.groupby(['domain', 'subreddit','classify']).count().reset_index()\n",
    "df_pivot_count.columns = [['domain','subreddit','classify', 'submissions']]\n",
    "df_pivot_count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>classify</th>\n",
       "      <th>submissions</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>total_upvotes</th>\n",
       "      <th>update_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.bp.blogspot.com</td>\n",
       "      <td>travel</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>4980</td>\n",
       "      <td>4980</td>\n",
       "      <td>10/21/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11alive.com</td>\n",
       "      <td>upliftingnews</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>25082</td>\n",
       "      <td>25082</td>\n",
       "      <td>10/21/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12160.info</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>5586</td>\n",
       "      <td>5586</td>\n",
       "      <td>10/21/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1800contacts.com</td>\n",
       "      <td>freebies</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>670</td>\n",
       "      <td>670</td>\n",
       "      <td>10/21/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.media.tumblr.com</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>697</td>\n",
       "      <td>697</td>\n",
       "      <td>10/21/2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                domain      subreddit classify  submissions  avg_score  \\\n",
       "0    1.bp.blogspot.com         travel    other            1       4980   \n",
       "1          11alive.com  upliftingnews    other            1      25082   \n",
       "2           12160.info     conspiracy    other            1       5586   \n",
       "3     1800contacts.com       freebies    other            1        670   \n",
       "4  24.media.tumblr.com     reddit.com    other            1        697   \n",
       "\n",
       "   total_upvotes update_date  \n",
       "0           4980  10/21/2017  \n",
       "1          25082  10/21/2017  \n",
       "2           5586  10/21/2017  \n",
       "3            670  10/21/2017  \n",
       "4            697  10/21/2017  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_final = pd.merge(df_pivot_count, df_pivot_avg, how='left', on=['domain','subreddit', 'classify'])\n",
    "df_pivot_final['total_upvotes'] = (df_pivot_final.submissions*df_pivot_final.avg_score)\n",
    "date = []\n",
    "# For each row in the column,\n",
    "for row in df_pivot_final['domain']:\n",
    "    # Append a letter grade\n",
    "    date.append(time.strftime(\"%m/%d/%Y\"))\n",
    "# Create a column from the list\n",
    "df_pivot_final['update_date'] = date\n",
    "df_pivot_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### taking subreddit out for now, if I want to pull in, just skip straight to pushing to DB, adding subreddit field in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>classify</th>\n",
       "      <th>submissions</th>\n",
       "      <th>total_upvotes</th>\n",
       "      <th>update_date</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.bp.blogspot.com</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>4980</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11alive.com</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>25082</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>25082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12160.info</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>5586</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1800contacts.com</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>670</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.media.tumblr.com</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>697</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3ammagazine.com</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>451</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5050.degstu.com</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>10005</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68.media.tumblr.com</td>\n",
       "      <td>image/video</td>\n",
       "      <td>2</td>\n",
       "      <td>49011</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>24505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99percentinvisible.org</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9news.com</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>16261</td>\n",
       "      <td>10/21/2017</td>\n",
       "      <td>16261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   domain     classify  submissions  total_upvotes  \\\n",
       "0       1.bp.blogspot.com        other            1           4980   \n",
       "1             11alive.com        other            1          25082   \n",
       "2              12160.info        other            1           5586   \n",
       "3        1800contacts.com        other            1            670   \n",
       "4     24.media.tumblr.com        other            1            697   \n",
       "5         3ammagazine.com        other            1            451   \n",
       "6         5050.degstu.com        other           23          10005   \n",
       "7     68.media.tumblr.com  image/video            2          49011   \n",
       "8  99percentinvisible.org        other            1            608   \n",
       "9               9news.com        other            1          16261   \n",
       "\n",
       "  update_date  avg_score  \n",
       "0  10/21/2017       4980  \n",
       "1  10/21/2017      25082  \n",
       "2  10/21/2017       5586  \n",
       "3  10/21/2017        670  \n",
       "4  10/21/2017        697  \n",
       "5  10/21/2017        451  \n",
       "6  10/21/2017        435  \n",
       "7  10/21/2017      24505  \n",
       "8  10/21/2017        608  \n",
       "9  10/21/2017      16261  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot_final_nosub = df_pivot_final[['domain','classify','submissions','total_upvotes']]\n",
    "df_pivot_final_nosub = df_pivot_final_nosub.groupby(['domain','classify']).sum().reset_index()\n",
    "\n",
    "# Create a list to store current date\n",
    "date = []\n",
    "# For each row in the column,\n",
    "for row in df_pivot_final_nosub['domain']:\n",
    "    # Append a letter grade\n",
    "    date.append(time.strftime(\"%m/%d/%Y\"))\n",
    "# Create a column from the list\n",
    "df_pivot_final_nosub['update_date'] = date\n",
    "df_pivot_final_nosub['avg_score'] = (df_pivot_final_nosub.total_upvotes/df_pivot_final_nosub.submissions)\n",
    "df_pivot_final_nosub.avg_score = df_pivot_final_nosub.avg_score.astype(int)\n",
    "df_pivot_final_nosub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clear old domains from collection before dropping new ones in\n",
    "result = db.domains.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#push to collection\n",
    "for index, row in df_pivot_final_nosub.iterrows():\n",
    "    dic = {'domain': row['domain'],\n",
    "       'submissions': row['submissions'],\n",
    "       'avg_score': row['avg_score'],\n",
    "       'total_upvotes': row['total_upvotes'],\n",
    "       'update_date': row['update_date'],\n",
    "       'classify': row['classify']\n",
    "      }\n",
    "    result = db.domains.insert_one(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_pivot_final_nosub.to_csv('/Users/erikrood/desktop/df_pivot_final_nosub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
