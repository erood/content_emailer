{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Main function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__v</th>\n",
       "      <th>_id</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>email</th>\n",
       "      <th>frequency</th>\n",
       "      <th>password</th>\n",
       "      <th>subreddits</th>\n",
       "      <th>updatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5aa43b833b376b0014ed6a32</td>\n",
       "      <td>2018-03-10 20:09:39.140</td>\n",
       "      <td>erood20@gmail.com</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>$2a$10$6h./TMntFPEH29S7lffCKO7wOjpBpe7IPGQ9FBQ...</td>\n",
       "      <td>dataisbeautiful,programming</td>\n",
       "      <td>2018-03-10 20:29:40.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5aa5e8955e26ee00142ae085</td>\n",
       "      <td>2018-03-12 02:40:21.822</td>\n",
       "      <td>erood30@gmail.com</td>\n",
       "      <td>Daily</td>\n",
       "      <td>$2a$10$hbYZeAZBJks2W7.I1hyaReqQAUWDDBahQsgavXz...</td>\n",
       "      <td>EarthPorn,Fitness</td>\n",
       "      <td>2018-03-12 02:40:21.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5aaad86f86982a001464d03b</td>\n",
       "      <td>2018-03-15 20:32:47.312</td>\n",
       "      <td>crystalm@fb.com</td>\n",
       "      <td>Daily</td>\n",
       "      <td>$2a$10$zmOmczlBNsazoC.qMZFu1eiBRp4bPP4rQj76/KS...</td>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>2018-03-15 20:32:47.312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   __v                       _id               createdAt              email  \\\n",
       "0    0  5aa43b833b376b0014ed6a32 2018-03-10 20:09:39.140  erood20@gmail.com   \n",
       "1    0  5aa5e8955e26ee00142ae085 2018-03-12 02:40:21.822  erood30@gmail.com   \n",
       "2    0  5aaad86f86982a001464d03b 2018-03-15 20:32:47.312    crystalm@fb.com   \n",
       "\n",
       "  frequency                                           password  \\\n",
       "0    Weekly  $2a$10$6h./TMntFPEH29S7lffCKO7wOjpBpe7IPGQ9FBQ...   \n",
       "1     Daily  $2a$10$hbYZeAZBJks2W7.I1hyaReqQAUWDDBahQsgavXz...   \n",
       "2     Daily  $2a$10$zmOmczlBNsazoC.qMZFu1eiBRp4bPP4rQj76/KS...   \n",
       "\n",
       "                    subreddits               updatedAt  \n",
       "0  dataisbeautiful,programming 2018-03-10 20:29:40.086  \n",
       "1            EarthPorn,Fitness 2018-03-12 02:40:21.822  \n",
       "2                AdviceAnimals 2018-03-15 20:32:47.312  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#important command line function to get mongo uri -- \n",
    "# heroku config --app sheltered-ocean-45405 | grep MONGODB_URI\n",
    "#where you literally type in MONGODB_URI, generates code like such: mongodb://heroku_xph57032:sb1vurrej7o36g0jumoh534qpr@ds141108.mlab.com:41108/heroku_xph57032\n",
    "#the code is then fed into the client\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import numpy as np\n",
    "import csv, sys\n",
    "import praw\n",
    "import operator\n",
    "import datetime\n",
    "\n",
    "\n",
    "#set up praw\n",
    "reddit = praw.Reddit(client_id='D7tXhzmCZKD1Ig',\n",
    "                 client_secret='a8Cs1yp7GUakwc-Hzkd1twMRRcU',\n",
    "                 user_agent='Script for top domains posted on reddit')\n",
    "\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "\n",
    "client = MongoClient('mongodb://heroku_c6w3t5x5:k6orit3e4osatg7m04senkq3vn@ds163918.mlab.com:63918/heroku_c6w3t5x5')\n",
    "\n",
    "db = client['heroku_c6w3t5x5']\n",
    "\n",
    "users = db.users\n",
    "users = pd.DataFrame(list(users.find()))\n",
    "users.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop that will be cronned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SendEmail(to_email): \n",
    "    #gmail style docs: https://developers.google.com/gmail/design/css#example\n",
    "    import smtplib  \n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from email.mime.text import MIMEText\n",
    "\n",
    "    from_address = \"erood20@gmail.com\"\n",
    "    to_address = to_email\n",
    "\n",
    "    # Create message container - the correct MIME type is multipart/alternative.\n",
    "    msg = MIMEMultipart('alternative')\n",
    "    now = datetime.datetime.now()\n",
    "    subject_date = now.strftime(\"%m-%d-%Y\")\n",
    "    msg['Subject'] = \"Storyrake Summary - \"+subject_date\n",
    "    msg['From'] = from_address\n",
    "    msg['To'] = to_address\n",
    "\n",
    "    # Create the body of the message (a plain-text and an HTML version).\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head>\n",
    "        <style>\n",
    "          .colored {\n",
    "            font-size:16px;\n",
    "          }\n",
    "           .footer {\n",
    "            font-size:12px;\n",
    "            font-color: #777;\n",
    "          }\n",
    "          .reddit_table {\n",
    "            border-spacing: 25px;\n",
    "            font-size:16px;\n",
    "            padding-left:0px;\n",
    "\n",
    "          }\n",
    "          .row_title {\n",
    "            font-weight:bold;\n",
    "            color:#115fd8;\n",
    "\n",
    "            }\n",
    "          .container{\n",
    "            padding-left:20px;\n",
    "        \n",
    "          }\n",
    "          .col-md-8{\n",
    "          max-width:75%;\n",
    "        \n",
    "          }\n",
    "\n",
    "          #body {\n",
    "            font-size:16px;\n",
    "          }\n",
    "          #tr {\n",
    "\n",
    "        }\n",
    "        </style>\n",
    "      </head>\n",
    "      <div class=\"container\">\n",
    "      <body>\n",
    "        <p class='colored'>Hi,<br>\n",
    "        <br>\n",
    "        Below is your Reddit summary:\n",
    "        </p>\n",
    "        \"\"\"\n",
    "\n",
    "    html +=\\\n",
    "    \"\"\"\n",
    "    <div class=\"col-md-8\">\n",
    "    <hr>\n",
    "    <table class=\"reddit_table\">\n",
    "    <thead class=\"row_title\">\n",
    "    <td>Subreddit</td><td>Link</td><td>Score</td><td>Date</td>\n",
    "    </thead>\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in df_final.iterrows():\n",
    "        html+=\"<tr><td>%s</td><td><a href=%s>%s</a></td><td>%s</td><td>%s</td></tr>\" %(row['subreddit'], row['url'],row['title'], row['score'], row['time'])\n",
    "\n",
    "    html+=\\\n",
    "    \"\"\"\n",
    "    </table>\n",
    "    <hr>\n",
    "    </div>\n",
    "\n",
    "    <p class='footer'>\n",
    "    <i>To add/remove subreddits, change your preferred frequency, or unsubscribe <a href=www.erikrood.com>click here</a><i>. \n",
    "    </p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    # Record the MIME types of both parts - text/plain and text/html.\n",
    "    part2 = MIMEText(html, 'html')\n",
    "\n",
    "    # Attach parts into message container.\n",
    "    # According to RFC 2046, the last part of a multipart message, in this case\n",
    "    # the HTML message, is best and preferred.\n",
    "    msg.attach(part2)\n",
    "\n",
    "\n",
    "    # Credentials (if needed)  \n",
    "    #username = 'erood20@gmail.com'  \n",
    "    #password = 'uoyuktglpyvxqycv'  \n",
    "    username = 'storyrake@gmail.com'\n",
    "    password = 'zgatluyspdmsakag'\n",
    "\n",
    "\n",
    "    # The actual mail send  \n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.login(username,password)  \n",
    "    server.sendmail(from_address, to_address, msg.as_string())  \n",
    "    server.quit()  \n",
    "\n",
    "    \n",
    "\n",
    "#MAIN \n",
    "\n",
    "\n",
    "for index, row in users.iterrows():\n",
    "    if row['frequency'] == 'Daily':\n",
    "        \n",
    "        #variables\n",
    "        praw_freq = 'day'\n",
    "        to_email = row['email']\n",
    "        s_list = row['subreddits']\n",
    "        s_list = s_list.split(\",\")\n",
    "\n",
    "        \n",
    "        ### Crawl reddit, clean output ###\n",
    "        #dictionaries\n",
    "        domains_sub = {}\n",
    "        domains_score = {}\n",
    "        domains_title = {}\n",
    "        domains_time = {}\n",
    "\n",
    "        #loop through list of subreddits\n",
    "        for i in s_list:\n",
    "\n",
    "            #--Pull in score for given submission id--#\n",
    "            subreddit = reddit.subreddit(i)   \n",
    "            submissions = subreddit.top(praw_freq, limit=5)\n",
    "\n",
    "            #sum score across submissions\n",
    "            for s in submissions:\n",
    "                if s.id in domains_score.keys():\n",
    "                    domains_score[s.id] += s.score\n",
    "                else:\n",
    "                    domains_score[s.id] = s.score\n",
    "\n",
    "            df_score = pd.DataFrame.from_dict(domains_score, orient='index').reset_index()\n",
    "            df_score.columns = ['id','score']\n",
    "\n",
    "\n",
    "            #--Grab subreddit for given submission ID--#\n",
    "            subreddit = reddit.subreddit(i)\n",
    "            submissions = subreddit.top(praw_freq, limit=5)\n",
    "\n",
    "\n",
    "            for s in submissions:\n",
    "                if s.id in domains_sub.keys():\n",
    "                    #(1) works for generating total score:\n",
    "                    domains_sub[s.id] = s.subreddit.display_name\n",
    "                else:\n",
    "                    #(2)\n",
    "                    #works for generating total score:\n",
    "                    domains_sub[s.id] = s.subreddit.display_name\n",
    "\n",
    "\n",
    "\n",
    "            #--Grab title for given submission ID--#        \n",
    "            subreddit = reddit.subreddit(i)   \n",
    "            submissions = subreddit.top(praw_freq, limit=5)\n",
    "\n",
    "            for s in submissions:\n",
    "                if s.id in domains_title.keys():\n",
    "                    #(1) works for generating total score:\n",
    "                    domains_title[s.id] = s.title\n",
    "                else:\n",
    "                    #(2)\n",
    "                    #works for generating total score:\n",
    "                    domains_title[s.id] = s.title\n",
    "\n",
    "\n",
    "\n",
    "            #--Grab time for given submission ID--#        \n",
    "            subreddit = reddit.subreddit(i)   \n",
    "            submissions = subreddit.top(praw_freq, limit=50)\n",
    "\n",
    "            for s in submissions:\n",
    "                if s.id in domains_time.keys():\n",
    "                    #(1) works for generating total score:\n",
    "                    domains_time[s.id] = datetime.datetime.fromtimestamp(s.created).date() #datetime.datetime.fromtimestamp(s.created)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    #(2)\n",
    "                    #works for generating total score:\n",
    "                    domains_time[s.id] = datetime.datetime.fromtimestamp(s.created).date()\n",
    "\n",
    "        df_subreddit = pd.DataFrame.from_dict(domains_sub, orient='index').reset_index()\n",
    "        df_subreddit.columns = ['id','subreddit']\n",
    "\n",
    "        df_title = pd.DataFrame.from_dict(domains_title, orient='index').reset_index()\n",
    "        df_title.columns = ['id','title']\n",
    "\n",
    "        df_time = pd.DataFrame.from_dict(domains_time, orient='index').reset_index()\n",
    "        df_time.columns = ['id','time']\n",
    "\n",
    "\n",
    "        #merge the three tables together, using submission ID as primary key\n",
    "        df_sub_score = df_subreddit.merge(df_score, how='left', on=\"id\")\n",
    "        df_title_score_sub = df_sub_score.merge(df_title, how='left', on='id')\n",
    "        df_final = df_title_score_sub.merge(df_time, how='left', on='id')\n",
    "\n",
    "\n",
    "        # Add in submission URL using the 'id' \n",
    "        df_final['url'] = ['www.reddit.com/']+df_final['id'].astype(str) \n",
    "\n",
    "        #sort by highest score\n",
    "        df_final = df_final.sort_values(['subreddit', 'score'], ascending=[True, False])\n",
    "\n",
    "        #chop down to just subreddit, score, time, url\n",
    "        df_final = df_final[['subreddit','score','time','url','title']]\n",
    "\n",
    "        #only keep top X for given subreddit\n",
    "        df_final = df_final.groupby('subreddit').head(5)\n",
    "        \n",
    "        ### Send email ###\n",
    "        SendEmail(to_email)\n",
    "                \n",
    "        \n",
    "    elif row['frequency'] == 'Weekly' and datetime.datetime.today().weekday() == 3:\n",
    "        \n",
    "        #variables\n",
    "        praw_freq = 'week'\n",
    "        to_email = row['email']\n",
    "        s_list = row['subreddits']\n",
    "        s_list = s_list.split(\",\")\n",
    "\n",
    "        \n",
    "        ### Crawl reddit, clean output ###\n",
    "        #dictionaries\n",
    "        domains_sub = {}\n",
    "        domains_score = {}\n",
    "        domains_title = {}\n",
    "        domains_time = {}\n",
    "\n",
    "        #loop through list of subreddits\n",
    "        for i in s_list:\n",
    "\n",
    "            #--Pull in score for given submission id--#\n",
    "            subreddit = reddit.subreddit(i)   \n",
    "            submissions = subreddit.top(praw_freq, limit=5)\n",
    "\n",
    "            #sum score across submissions\n",
    "            for s in submissions:\n",
    "                if s.id in domains_score.keys():\n",
    "                    domains_score[s.id] += s.score\n",
    "                else:\n",
    "                    domains_score[s.id] = s.score\n",
    "\n",
    "            df_score = pd.DataFrame.from_dict(domains_score, orient='index').reset_index()\n",
    "            df_score.columns = ['id','score']\n",
    "\n",
    "\n",
    "            #--Grab subreddit for given submission ID--#\n",
    "            subreddit = reddit.subreddit(i)\n",
    "            submissions = subreddit.top(praw_freq, limit=5)\n",
    "\n",
    "\n",
    "            for s in submissions:\n",
    "                if s.id in domains_sub.keys():\n",
    "                    #(1) works for generating total score:\n",
    "                    domains_sub[s.id] = s.subreddit.display_name\n",
    "                else:\n",
    "                    #(2)\n",
    "                    #works for generating total score:\n",
    "                    domains_sub[s.id] = s.subreddit.display_name\n",
    "\n",
    "\n",
    "\n",
    "            #--Grab title for given submission ID--#        \n",
    "            subreddit = reddit.subreddit(i)   \n",
    "            submissions = subreddit.top(praw_freq, limit=5)\n",
    "\n",
    "            for s in submissions:\n",
    "                if s.id in domains_title.keys():\n",
    "                    #(1) works for generating total score:\n",
    "                    domains_title[s.id] = s.title\n",
    "                else:\n",
    "                    #(2)\n",
    "                    #works for generating total score:\n",
    "                    domains_title[s.id] = s.title\n",
    "\n",
    "\n",
    "\n",
    "            #--Grab time for given submission ID--#        \n",
    "            subreddit = reddit.subreddit(i)   \n",
    "            submissions = subreddit.top(praw_freq, limit=50)\n",
    "\n",
    "            for s in submissions:\n",
    "                if s.id in domains_time.keys():\n",
    "                    #(1) works for generating total score:\n",
    "                    domains_time[s.id] = datetime.datetime.fromtimestamp(s.created).date() #datetime.datetime.fromtimestamp(s.created)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    #(2)\n",
    "                    #works for generating total score:\n",
    "                    domains_time[s.id] = datetime.datetime.fromtimestamp(s.created).date()\n",
    "\n",
    "        df_subreddit = pd.DataFrame.from_dict(domains_sub, orient='index').reset_index()\n",
    "        df_subreddit.columns = ['id','subreddit']\n",
    "\n",
    "        df_title = pd.DataFrame.from_dict(domains_title, orient='index').reset_index()\n",
    "        df_title.columns = ['id','title']\n",
    "\n",
    "        df_time = pd.DataFrame.from_dict(domains_time, orient='index').reset_index()\n",
    "        df_time.columns = ['id','time']\n",
    "\n",
    "\n",
    "        #merge the three tables together, using submission ID as primary key\n",
    "        df_sub_score = df_subreddit.merge(df_score, how='left', on=\"id\")\n",
    "        df_title_score_sub = df_sub_score.merge(df_title, how='left', on='id')\n",
    "        df_final = df_title_score_sub.merge(df_time, how='left', on='id')\n",
    "\n",
    "\n",
    "        # Add in submission URL using the 'id' \n",
    "        df_final['url'] = ['www.reddit.com/']+df_final['id'].astype(str) \n",
    "\n",
    "        #sort by highest score\n",
    "        df_final = df_final.sort_values(['subreddit', 'score'], ascending=[True, False])\n",
    "\n",
    "        #chop down to just subreddit, score, time, url\n",
    "        df_final = df_final[['subreddit','score','time','url','title']]\n",
    "\n",
    "        #only keep top X for given subreddit\n",
    "        df_final = df_final.groupby('subreddit').head(5)\n",
    "        \n",
    "        ### Send email ###\n",
    "        SendEmail(to_email)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples/notes below here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly run\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "for index, row in users.iterrows():\n",
    "    if row['frequency'] == 'Daily':\n",
    "        print(\"yes\")\n",
    "    elif row['frequency'] == 'Weekly' and datetime.datetime.today().weekday() == 2:  #2 = wednesday\n",
    "        print('weekly run')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<tr><td>EarthPorn</td><td><a href=www.reddit.com/8080ml>Best waterfalls in the states? Oregon, in my opinion.. [OC] [2400 x 3000]</a></td><td>66625</td><td>2018-02-25</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>EarthPorn</td><td><a href=www.reddit.com/836t67>I was one of two people who got to witness the surf from yesterday's nor'easter hit the shores of Acadia National Park. [OC][1622x2048]</a></td><td>53817</td><td>2018-03-09</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>EarthPorn</td><td><a href=www.reddit.com/80dzh3>Woke up at 5 AM to shoot this characteristic tree in foggy conditions, The Netherlands [OC][1920x1280]</a></td><td>51614</td><td>2018-02-26</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>EarthPorn</td><td><a href=www.reddit.com/826upc>This is my favorite shot I've ever taken in Glacier National Park. [OC][2560*1707]</a></td><td>49982</td><td>2018-03-05</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>EarthPorn</td><td><a href=www.reddit.com/7yi5g9>Rawson Lake, Peter Lougheed Provincial Park, Alberta, Canada[OC][4097x2969]</a></td><td>48192</td><td>2018-02-18</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>Fitness</td><td><a href=www.reddit.com/7ye7r2>How to do PULL UPS properly and how to do your first pullup if you can't do any. 💪</a></td><td>12817</td><td>2018-02-18</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>Fitness</td><td><a href=www.reddit.com/7y6h3n>M/35 - best shape of my life so far</a></td><td>3002</td><td>2018-02-17</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>Fitness</td><td><a href=www.reddit.com/8002c2>Just Wanted to Share my Progress.</a></td><td>2646</td><td>2018-02-24</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>Fitness</td><td><a href=www.reddit.com/7xjdq6>Greg Nuckols - \"Avoiding Cardio Could Be Holding You Back\"</a></td><td>2553</td><td>2018-02-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>Fitness</td><td><a href=www.reddit.com/82zxep>Examine.com updated their \"how much protein do I need?\"</a></td><td>1966</td><td>2018-03-08</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#html scrap (working w/ loops)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "for index, row in df_final.iterrows():\n",
    "    display(HTML((\"<tr><td>%s</td><td><a href=%s>%s</a></td><td>%s</td><td>%s</td></tr>\" %(row['subreddit'], row['url'],row['title'], row['score'], row['time']))))\n",
    "    \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<tr><td>EarthPorn</td><td></td><td></td><td></td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84d5q7>Snowy morning in Connecticut [OC] [2784 x 4176]</a></td><td>16747</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/848lfn>Stratovolcano. Brokentop Mountain. Bend, OR. USA. 4752 x3168 [OC]</a></td><td>15003</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84a33d>Stones that look like mushrooms. Goblin Valley, Utah [OC][4000x6000]</a></td><td>13363</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84dngm>Snow Moon sets over Ruby Mountain, Colorado [OC] [4000x2676]</a></td><td>2955</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84ejce>I've been on my bike in Vietnam for a while now, and the scenery never gets old - Tuan Giao / Than Yuen [OC][6000 × 3331]</a></td><td>2447</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td>Fitness</td><td></td><td></td><td></td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84c866>Rant Wednesday</a></td><td>166</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84b5rt>Why are more reps harder than strength training?</a></td><td>138</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84ap2b>Shin splints</a></td><td>91</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84fm98>I created a Rice Bucket Routine that you can do daily to supplement your grip strength. It's short, but effective!</a></td><td>68</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<tr><td><a href=www.reddit.com/84c87d>Quarterly Fitness Pro-Tips Megathread!</a></td><td>49</td><td>2018-03-14</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to put one subreddit as row above links\n",
    "for index, row in df_final.iterrows():\n",
    "    if index % 5 == 0:\n",
    "        display(HTML((\"<tr><td>%s</td><td></td><td></td><td></td></tr>\" %(row['subreddit'] ))))\n",
    "    else:\n",
    "        pass\n",
    "    display(HTML((\"<tr><td><a href=%s>%s</a></td><td>%s</td><td>%s</td></tr>\" %(row['url'],row['title'], row['score'], row['time']))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-15-2018'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "now.strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
